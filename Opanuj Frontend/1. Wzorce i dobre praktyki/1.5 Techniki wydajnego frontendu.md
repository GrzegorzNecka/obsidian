**Wprowadzenie**

W poprzednich lekcjach:

- poznałeś wzorce i dobre praktyki rozwijania kodu na frontendzie
    
- poznałeś sposoby na zarządzanie stanem aplikacji w kontrolowany sposób
    
- poznałeś techniki skutecznej komunikacji http
    

Chociaż każda z tych lekcji wpływała pośrednio na końcową jakość aplikacji (o czym szerzej w drugim module), to do tej pory przede wszystkim skupialiśmy się na inżynieryjnej stronie rozwijania naszych projektów. Warto jednak pamiętać, że z perspektywy odbiorcy naszej pracy, stosowanie (lub nie) konkretnego wzorca projektowego, języka programowania czy biblioteki jest drugorzędne.

Dlatego właśnie w tej lekcji idziemy krok dalej, poznając metody i techniki budowania aplikacji przyjaznych użytkownikowi końcowemu. Poznamy obiektywne i subiektywne sposoby oceny jakości aplikacji, zobaczymy jakie anty-wzorce pojawiają się w aplikacjach client-side, a następnie nauczymy się zarządzania często pojawiającymi się problemami.

Ta wiedza pozwoli ci bardziej świadomie wdrażać wszystkie porady przedstawione w pierwszym module kursu Opanuj Frontend: AI Edition.

## Ocena jakości aplikacji

Oceniając jakość aplikacji musimy brać pod uwagę zarówno obiektywne metryki i narzędzia oceniające tworzony produkt, jak i subiektywne wrażenia użytkowników, którzy zdecydowanie nie chcą wchodzić w rolę testerów.

### Doświadczenia osobiste

W czasach, kiedy każdy z nas jest podłączony do internetu całą dobę, a nasze smartfony i komputery pozwalają nieustannie zmieniać i testować nowe aplikacje, jakość tworzonych przez programistów rozwiązań jest poddawana nieustannej próbie.

Żeby przekonać się jak bardzo wymagający stali się użytkownicy, wystarczy tylko odwiedzić miejsca takie jak sklep Google Play czy App Store i poczytać recenzje publikowanych tam nowości. Jeśli aplikacja ładuje się zbyt wolno, stan użytkownika nie jest przechowywany w poprawny sposób, a nawigacje i zmiany widoków zajmują długie minuty, użytkownicy natychmiast porzucą nasze rozwiązanie w poszukiwaniu lepszych alternatyw.

> Wg badań firmy Google z 2016r., aż 53% wizyt jest porzucanych jeśli strona na urządzeniu mobilnym ładuje się **dłużej niż 3 sekundy**. Jeśli ładowanie zajmuje aż 10 sekund, szansa porzucenia wizyty wzrasta o 123% - [źródło](https://www.thinkwithgoogle.com/consumer-insights/consumer-trends/mobile-site-load-time-statistics/) / [źródło](https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/mobile-page-speed-new-industry-benchmarks/)

![[Pasted image 20240510130457.png]]


W kontekście aplikacji frontendowych, na tzw. “**perceived performance**”, czyli subiektywnie odczuwaną wydajność i jakość aplikacji, może wpływać m.in.:

- obsługa stanów ładowania aplikacji (czy użytkownik wie co właściwie się dzieje?)
    
- obsługa błędów w aplikacji (czy użytkownik może ponowić akcję?)
    
- obsługa pogorszonego połączenia z internetem i trybu offline (czy dane pozostają na ekranie?)
    
- obsługa dużych i małych zbiorów danych (czy lista z tysiącami elementów zamraża interfejs?)
    
- feedback aplikacji do akcji użytkownika (czy użytkownik wie o poprawnie wykonanej akcji?)
    
- szybkość ładowania zasobów takich jak obrazki i pliki (czy użytkownik traci pakiet danych?)
    
- przewidywalne zachowanie interfejsu użytkownika (czy elementy pozostają na swoim miejscu?)
    

Wszystkie te czynniki wpływają na to, jakie skojarzenia ma użytkownik myśląc o naszej aplikacji. Jeśli będą to skojarzenia pozytywne, możemy się spodziewać dalszego polecania i rekomendacji. Jeśli będą to skojarzenia negatywne, to spadek aktywności szybko pokaże nam monitoring, a o konsekwencjach poinformuje szef albo dział finansów.

Na potrzeby tej lekcji przygotowaliśmy aplikację, którą postaramy się zoptymalizować wdrażając konkretne metody i narzędzia poprawiające doświadczenia użytkownika.

Zobacz, jak wygląda jej stan początkowy:


Główne problemy, które można zauważyć na pierwszy rzut oka, to:

- długi czas ładowania komponentów
    

- długi czas ładowania danych (artykułów, komentarzy, autorów)
    
- długi czas oczekiwania na akcje użytkownika (zapis komentarza)
    
- brak informacji zwrotnej dla użytkownika (zarówno w trakcie ładowania i zapisywania danych)
    

Zanim przejdziemy do rozwiązywania tych problemów, zobaczmy jeszcze, jakie narzędzia mogą nam pomóc ocenić stan naszej aplikacji w bardziej obiektywny sposób.

### Obiektywne metryki

Obecnie najpopularniejszymi metrykami, względem których możemy porównywać jakość stron i aplikacji internetowych, są wskaźniki **Web Vitals** rozwijane przez Google.

> Web Vitals - an initiative to provide unified guidance for quality signals that are essential to delivering a great user experience on the web. - [źródło](https://web.dev/explore/learn-core-web-vitals)

Google zaznacza, że Web Vitals to wskaźniki, które będą ewoluować wraz z tym, jak zmienia się nasz sposób korzystania z internetu i aplikacji webowych. Mają one również promować dobre praktyki budowania interfejsów użytkownika pod kątem użytkownika końcowego, a nie technicznych statystyk pokroju szybkości odpowiedzi z backendu lub ilości bajtów, które pobiera przeglądarka.

Na dzisiaj (do 12 marca 2024r.) w skład tzw. Core Web Vitals wchodzą trzy metryki:

[**Largest Contentful Paint (LCP)**](https://web.dev/articles/lcp): to metryka skupiona na pomiarze odczuwalnej szybkości ładowania strony internetowej, mierzona do czasu pojawienia się na ekranie najważniejszej treści dla użytkownika. Czym jest ta najważniejsza treść? Dla ułatwienia pomiarów, za referencję przyjmuje się największy element interaktywny (img, image, video) lub blok tekstu, który wyświetla przeglądarka w trakcie wejścia na stronę po raz pierwszy.

Wartość docelowa dla LCP to czas poniżej 2.5 sekundy, powyżej 4s strona uważana jest za zbyt wolną.

Pamiętaj, że LCP nie oznacza wprost “pełnego załadowania się strony”, co dobrze pokazuje zestaw screenshotów ze strony web.dev (poniżej). Za element istotny dla LCP uznaje się największy blok tekstu, który jest widoczny na początkowych etapach ładowania strony. Mniejsze elementy nie wpływają na tę metrykę:

![[Pasted image 20240510130541.png]]

[(źródło)](https://web.dev/articles/lcp)

[**Cumulative Layout Shift (CLS)**](https://web.dev/articles/cls): to metryka określająca stabilność layoutu stron i aplikacji internetowych. Stabilność określa się mierząc zachowanie poszczególnych elementów na stronie, oraz wpływ ich ładowania na całościowy wygląd strony internetowej. Ma ona zapobiec umieszczaniu na stronie niekontrolowanych, dynamicznie zmieniających rozmiar fontów, widgetów i wszystkich innych osadzanych elementów, które w trakcie ładowania wpływają na sąsiednie fragmenty DOM. Z jej mierzenia wyklucza się akcje zainicjowane przez użytkownika (tutaj interaktywność jest oczekiwana i zrozumiała).

Szczegółowy algorytm pomiaru CLS znajdziesz [w tym miejscu](https://web.dev/articles/cls).

![[Pasted image 20240510130552.png]][(źródło)](https://web.dev/articles/cls)

Relatywna wartość docelowa dla CLS to poniżej 0.1, a powyżej 0.25 interfejs uważany jest za niestabilny.

[**First Input Delay (FID)**](https://web.dev/articles/fid): ta metryka określa czas, jaki upływa od pierwszej interakcji użytkownika ze stroną (kliknięcie w link, przycisk, wysłanie formularza), do czasu obsługi zdarzenia przez przeglądarkę. Mierzenie FID ma pomóc optymalizować interfejs i umożliwiać jak najszybszą interakcję użytkownika z tym, co zobaczył na ekranie. Negatywny wpływ na FID może mieć ładowanie i procesowanie dużego fragmentu kodu JavaScript, co blokuje główny wątek przeglądarki do czasu zinterpretowania całej treści.

Wartość docelowa dla FID to czas poniżej 100ms, powyżej 300ms aplikacja uważana jest za zbyt wolną.

**Ważne - od 12 marca 2024r. metryka FID zostanie zamieniona przez INP:**

[Interaction to Next Paint (INP)](https://web.dev/articles/inp): INP to metryka, która w założeniu ma lepiej oddawać tę część audytu, która wcześniej była mierzona przez FID. O ile FID skupiał się na czasie obsługi pierwszej interakcji ze stroną i głównie dotyczył etapu ładowania aplikacji, INP będzie mierzone na przekroju całej historii aktywności użytkownika ze stroną - już po tym, jak została załadowana. A co właściwie będzie mierzone? Czas od [interakcji użytkownika](https://web.dev/articles/inp#whats_in_an_interaction) do odmalowania interfejsu (tzw. render). Negatywny wpływ na INP może mieć złożony kod JavaScript i wykonywanie operacji obciążających zasoby użytkownika w przeglądarce.

![[Pasted image 20240510130609.png]]


[(źródło)](https://web.dev/articles/inp)

Wartość docelowa dla INP to czas poniżej 200ms, powyżej 500ms aplikacja uważana jest za zbyt wolną.

**Pomiar metryk Web Vitals w przeglądarce**

W narzędziach developerskich przeglądarki Chrome masz możliwość wykonania audytu pod kątem Core Web Vitals:

(Na powyższym filmie pomiar metryk realizujemy w trybie developerskim. W praktyce taki audyt warto przeprowadzić na produkcji, z ostatecznym zestawem tego, co ląduje w przeglądarce użytkownika.)

Audyt online zrealizujesz na stronie [PageSpeed Insights](https://pagespeed.web.dev/).

## Optymalizacja strony

Przejdźmy teraz przez konkretne techniki optymalizacji naszej aplikacji, które spowodują poprawę doświadczeń użytkownika. Fragmenty prezentowanego kodu będą stworzone we frameworku React, jednak nasze porady bez problemu zastosujesz w każdej popularnej technologii frontendowej.

**Profilowanie i rzut oka na kod**

W pierwszym kroku - jeszcze przed rozwiązaniem jakiegokolwiek problemu - zajmiemy się profilowaniem aplikacji.  
  
Profilowanie aplikacji to proces analizy działania aplikacji w celu identyfikacji miejsc, które mogą być źródłem problemów z wydajnością, takich jak wolne działanie, nadmierne zużycie pamięci, lub inne zasoby systemowe. Umożliwia to zrozumienie, jak aplikacja wykonuje poszczególne fragmenty kodu w czasie rzeczywistym. Dzięki profilowaniu aplikacji możliwe jest identyfikowanie wąskich gardeł, które mogą wpływać na ogólną wydajność aplikacji.

Jedno z takich wąskich gardeł (_bottleneck_) odkrywamy na filmie poniżej:


**Optymalizacja pierwszego zapytania**

Jak rozwiązać problem zapytania HTTP, które blokuje szybki start naszej aplikacji? Popularną techniką, która znana była na długo przed wzrostem popularności nowoczesnych frameworków frontendowych, jest zastosowanie Server-Side Renderingu (SSR).

SSR to technika, gdzie możliwe do zoptymalizowania operacje, takie jak pobieranie konkretnej porcji danych, delegujemy do części serwerowej naszej aplikacji. Na serwerze może się odbywać zarówno renderowanie pierwszej wersji komponentu, który zostanie później “ożywiony” w przeglądarce (tzw. _hydracja_), ale też budowanie i wstrzykiwanie danych do szablonów, z których korzysta nasza aplikacja.

Właśnie to drugie podejście zobaczysz na poniższym filmie:

Warto dodać, że nowoczesny frontend co raz częściej próbuje zacierać granicę pomiędzy warstwami aplikacji. Popularne technologie takie jak React i jego Server Components, czy framework Astro z architekturą wyspową, budują natywne wsparcie dla rozwijania komponentów zarówno na serwerze, jak i w przeglądarce.

Mówiąc o [Astro](https://astro.build/) (i poprzednikach takich jak [Gatsby](https://www.gatsbyjs.com/) czy [Eleventy](https://www.11ty.dev/)) należy jeszcze wspomnieć o tzw. SSG (Static-Site Generators), czyli generatorach stron statycznych. Są to frameworki, które z jednej strony pozwalają nam rozwijać kod w ulubionym frameworku, a z drugiej - już na etapie budowania aplikacji - minimalizują ilość dostarczanego do klienta JavaScriptu skupiając się na produkcji statycznych stron opartych o HTML. Wszędzie tam, gdzie priorytetem jest treść, a nie rozbudowany interfejs i interaktywne widgety, generatory stron statycznych sprawdzą się znakomicie.

Z naszej strony jeszcze raz rekomendujemy tutaj **Astro**, które wyrasta na lidera tego segmentu (co prawda Astro ma zdecydowanie większe możliwości niż SSG, ale o tym w osobnym materiale).

**Optymalizacja renderowania komponentów**

Kolejna optymalizacja, na którą możemy się zdecydować, dotyczy struktury komponentów i tego, kiedy i jakie dane zostają przez nie pobierane.

W przypadku dużych zapytań obsługujących całą stronę istnieje ryzyko, że jeden najwolniejszy zasób zablokuje te fragmenty aplikacji, które mogłyby być odblokowane zdecydowanie wcześniej.

Przykładowo, kiedy ładujemy za jednym podejściem:

- artykuły (w 0.5s)
    
- autorów (w 0.5s)
    
- komentarze (w 5s)
    

To ostatni zasób, czyli komentarze, niepotrzebnie wpływają na długi (5s) czas oczekiwania na artykuły i autorów, które są dostępne zdecydowanie wcześniej.

Jeden ze sposobów na rozwiązanie tego problemu zobaczysz na kolejnym przykładzie:


Co ważne, zaprezentowana tutaj optymalizacja nie jest tzw. “silver bulletem”, czyli rozwiązaniem, które powinieneś stosować zawsze i wszędzie. To tylko jedna z możliwości optymalizacji zapytań - może się okazać, że w twoim projekcie lepiej sprawdzi się mniejsza liczba zapytań niż wtedy, kiedy każdy komponent pyta backend o swoją porcję danych. Ostateczna decyzja należy do ciebie i wynika ze specyfiki aplikacji, którą rozwijasz.

**Dalsza optymalizacja komponentów**

W powyższym przykładzie, na skutek optymalizacji struktury komponentów, wprowadziliśmy niestety duplikację pobierania fragmentu danych z backendu. Problem i rozwiązanie zaprezentuje kolejny przykład, gdzie za lek na problemy posłuży nam [TanStack Query](https://tanstack.com/query/latest). To popularna biblioteka pobierania danych i synchronizacji stanu globalnego, która - choć wywodzi się z ekosystemu Reacta - zaczyna być teraz wdrażana w ekosystemach Angulara czy Svelte.

TanStack Query to biblioteka, która pozwala nam w deklaratywny sposób opisywać poszczególne zapytania do backendu, dzięki czemu może koordynować jak i kiedy dane zapytanie będzie wykonane. Jeśli zdarzy się, że dwa komponenty próbują niezależnie pobierać ten sam zasób, finalnie zostanie wysłane tylko jedno żądanie, a rezultat zostanie udostępniony w dwóch fragmentach aplikacji.

Jeśli pracujesz z Reactem, możesz porównać jej możliwości z alternatywami - [zobacz ten link](https://tanstack.com/query/latest/docs/framework/react/comparison).

Wielka trójka frameworków (React, Angular, Vue) eksperymentuje z natywnym sposobem kontrolowania komponentów takich jak stworzony przez nas **_<Placeholder />._**

W przypadku Reacta zadba o to [Suspense](https://react.dev/reference/react/Suspense):

```typescript
<Suspense fallback={<Placeholder />}>
  <SomeComponent />
</Suspense>
```

W przypadku Vue zadba o to… również [Suspense](https://vuejs.org/guide/built-ins/suspense.html) (chociaż realizowany nieco inaczej):

```typescript
<Suspense>
  <!-- component with nested async dependencies -->
  <Dashboard />

  <!-- loading state via #fallback slot -->
  <template #fallback>
    <Placeholder />
  </template>
</Suspense>
```

…a w przypadku Angulara zadba o to nowa [składnia](https://angular.dev/guide/defer) tzw. deferrable views (Angular 17+):

```typescript
@defer {
  <large-component />
} @loading (after 100ms; minimum 1s) {
  <placeholder />
}
```

Jak widać, raz przyswojona w naszym kursie wiedza przyda się w wielu kontekstach ;)

**Optymalizacja interakcji z formularzem**

W jakie kolejności powinniśmy aktualizować stan aplikacji - przed czy po zapisie danych na backendzie?

Powszechnie stosowaną praktyką jest aktualizowanie interfejsu już po tym, jak backend potwierdzi zapis przekazywanych do niego danych. Mamy gwarancję poprawnej kolejności zdarzeń, możemy obsługiwać błędy a także dawać szansę na ponowienie zapytania.

A co, jeśli chcielibyśmy odwrócić ogólnie przyjętą kolejność operacji?

Do złamania reguł zmotywuje nas cytat od samego Pablo Picasso:

> Learn the rules like a pro, so you can break them like an artist.

Szczegóły wspomnianego hooka _useOptimistic_ znajdziesz [w tym miejscu](https://react.dev/reference/react/useOptimistic).

**Optymalizacja pozostałych elementów aplikacji**

Temat optymalizacji aplikacji frontendowych jest tak szeroki, że z łatwością moglibyśmy na jego temat przygotować odrębny moduł w naszym kursie (jeśli taki moduł powstanie w tym roku, w ramach aktualizacji kursu dostaniesz do niego dostęp zupełnie za darmo). Postanowiliśmy jednak rozpocząć od uniwersalnych fundamentów, które możesz stopniowo testować i oceniać pod kątem użyteczności we własnych projektach.

Dodatkowe techniki i zmiany, które pozytywnie wpłyną na szybkość działania twojej aplikacji to m.in.:

- Budowanie aplikacji w trybie produkcyjnym, z minifikacją kodu i usunięciem nieużywanych elementów
    
- Optymalizacja obrazków przy pomocy biblioteki [Sharp](https://github.com/lovell/sharp) i [pluginu do Vite](https://github.com/FatehAK/vite-plugin-image-optimizer)
    
- Stosowanie tzw. _lazy modules_, czyli modułów, które są pobierane na żądanie
    
- Optymalizowanie długich list elementów przy pomocy virtual scrolla, np. [TanStack Virtual](https://tanstack.com/virtual/latest)
    
- Stosowanie specyficznych dla danego frameworka technik takich jak [Partial Prerendering](https://nextjs.org/learn/dashboard-app/partial-prerendering)
    
- Testowanie “frameworków nowej fali”, które starają się ograniczać ilość dostarczanego do przeglądarki kodu JavaScript (Svelte, Qwik, Astro)
    

---

## [👨‍💻](https://emojipedia.org/man-technologist) Ćwiczenia praktyczne:

- **👉 Zanim rozpoczniesz - Fragment pliku README.md o nazwie “Zasoby lokalne” opisuje, jak wykorzystać serwer developerski do symulowanego pobierania i zapisu danych. W oparciu o te dane możesz zrealizować poniższe ćwiczenia.**
    

- Zbuduj prostą aplikację, którą pozwoli ci przetestować możliwości TanStack Query w kontekście ulubionego frameworka
    
    - Zaimplementuj pobieranie listy danych z dwóch niezależnych komponentów i sprawdź, jak TanStack Query radzi sobie z optymalizowaniem zapytań.
        
    - Zaimplementuj dodawanie nowego obiektu i odświeżanie listy elementów - [useMutation](https://tanstack.com/query/latest/docs/framework/react/guides/mutations#mutation-side-effects).
        
    - Możesz stworzyć nowy fragment aplikacji w oparciu o ulubiony framework w folderze **practice**
        
- Stwórz aplikację demo, która korzysta z mechanizmu renderowania optymistycznego. Zaimplementuj odwracanie lub ponawianie zmian na wypadek wystąpienia błędów na serwerze.
    
    - Możesz wykorzystać aplikację z poprzedniego ćwiczenia i wykorzystać TanStack Query
        
    - Możesz wykorzystać istniejący kod - examples/module1/lesson5/app-performance/routes/AppV3.tsx
        
    - Możesz stworzyć nowy fragment aplikacji w oparciu o ulubiony framework w folderze **practice**
        

## [📚](https://emojipedia.org/books) **Materiały dodatkowe:**

- [https://react.dev/learn/synchronizing-with-effects](https://react.dev/learn/synchronizing-with-effects)
    

- [https://react.dev/learn/you-might-not-need-an-effect#fetching-data](https://react.dev/learn/you-might-not-need-an-effect#fetching-data)
    

- [https://web.dev/articles/optimize-long-tasks](https://web.dev/articles/optimize-long-tasks)