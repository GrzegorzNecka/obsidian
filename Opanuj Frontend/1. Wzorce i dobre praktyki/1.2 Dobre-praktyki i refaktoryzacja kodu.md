## Wprowadzenie

Jako programiści często zmagamy się z wyzwaniami utrzymania i rozwoju kodu, który musi pozostać czytelny, łatwy do zrozumienia i gotowy na zmiany. W tej lekcji przybliżymy ci zasady i podejścia, które pomogą ci osiągnąć założony cel.

Rozpoczniemy od zasady DRY, czyli "Don’t Repeat Yourself," która ma na celu eliminowanie zbędnych powtórzeń kodu i budowanie rozwiązań wielokrotnego użytku. Następnie przyjrzymy się pięciu zasadom SOLID, które wskazują, jak projektować kod, aby był łatwy w rozszerzaniu, ale odporny na zmiany, które mogłyby powodować nieoczekiwane problemy. Z kolei CUPID to zestaw mniej sztywnych wytycznych, które pozwolą ci ocenić jakość kodu pod kątem jego prostoty, przewidywalności i zgodności z ekosystemem.

Dowiesz się również, kiedy warto sięgać po zaawansowaną refaktoryzację, a kiedy wystarczy mała zmiana na poziomie komponentów.

### Klasyczne praktyki czystego kodu - DRY, SOLID, CUPID

**DRY**, czyli “Don’t Repeat Yourself” to jedna z najbardziej popularnych rekomendacji w świecie programowania.

W założeniu jej przesłanie jest jak najbardziej rozsądne - unikaj powtórzeń, buduj możliwe do ponownego użycia funkcje, moduły i biblioteki, oszczędzaj czas wprowadzając zmiany tylko w jednym miejscu. W przypadku prostych projektów to powinno zdecydowanie wystarczyć.

W praktyce okazuje się jednak, że do DRY powinniśmy podchodzić pragmatycznie. Okazjonalne powielenie fragmentu kodu nie jest natychmiastowym przepisem na porażkę, a sposobem na unikanie niepotrzebnych powiązań i tzw. “couplingu”. Zdarza się, że powtórzony w dwóch miejscach fragment kodu tylko przez chwilę pozostaje identyczny, a po chwili jeden z wariantów zaczyna ewoluować w nowym kierunku. Budowanie abstrakcji i gotowych na wszystkie przyszłe rozszerzenia modułów nie zawsze jest rozwiązaniem optymalnym.

DRY można też wprowadzać stopniowo. Nie zawsze trzeba zaczynać od budowania prawdziwie reużywalnej, możliwej do pobrania biblioteki, którą umieścimy na zewnątrz projektu. Jeśli algorytm w projekcie powtarza się dwa razy, to można zacząć od przesunięcia go do dedykowanego modułu, który następnie dwukrotnie zaimportujemy. Oszczędzimy czas, unikniemy duplikacji i zyskamy moment na lepszą ocenę sytuacji.

**SOLID** to z kolei zestaw pięciu zasad projektowania oprogramowania, które mówią o tym, że:

- Funkcja lub moduł powinny realizować jedno zadanie (Single Responsibility Principle    
- Kod powinien być otwarty na rozszerzenia i zamknięty na zmiany (Open-Closed Principle)
- Wymiana mniejszych fragmentów aplikacji nie powinna wymuszać aktualizacji całej architektury (Liskov Substitution Principle)
- Zamiast jednego ogólnego interfejsu stosuj kilka niezależnych od siebie (Interface Segregation Principle)
- Zewnętrzne zależności powinny być luźno powiązane z konsumentami i gotowe na wymianę (Dependency Inversion Principle)
![[Pasted image 20241213085545.png]]
O regułach SOLID napisano już dziesiątki artykułów i zakładamy, że prawdopodobnie nie spotykasz się z nimi po raz pierwszy w naszym kursie. Aby jednak sprawdzić, czy na pewno rozumiesz ich działanie, ćwiczenia na końcu tej lekcji pozwolą ci przetestować frontendowy SOLID w praktyce.

Jeśli reguły **SOLID** uważasz za mało przekonujące lub nie do końca odpowiadające twoim codziennym zadaniom, przyjrzyj się bliżej podejściu [**CUPID**](https://dannorth.net/cupid-for-joyful-coding/), które stawia na pierwszym miejscu przyjemność z kodowania.

W przeciwieństwie do mocno określonych zasad SOLIDnej piątki, CUPID to przede wszystkim “doświadczenia” i kierunek, w którym możesz stopniowo podążać refaktoryzując twój kod.

Autor podejścia CUPID, Dan North, wyjaśnia to w ten sposób:

> “Properties define a goal or centre to move towards. Your code is only closer to or further from the centre, and there is always a clear direction of travel. You can use properties as a lens or filter to assess your code and you can decide which ones to address next.” - Dan North

Zobacz czym charakteryzuje się kod zgodny z CUPID:

- Composable - Kod łatwy do wykorzystania ponownie, z określonym przeznaczeniem
- [Unix Philosophy](http://www.catb.org/~esr/writings/taoup/html/ch01s06.html) - Kod opierający się o małe, precyzyjne, łączące się ze sobą moduły
- Predictable - Kod robiący to, co na pierwszy rzut oka sugeruje jego architektura
- Idiomatic - Kod zgodny z ekosystemem i tradycją, w której powstał
- Domain-based - Kod korzystający z terminologii problemu, który rozwiązuje
    
![[Pasted image 20241213090210 1.png]]
W przeciwieństwie do reguł SOLID, CUPID nie skupia się na czarno-białym określeniu jakości kodu względem konkretnych praktyk. Jest to raczej pragmatyczny zestaw rekomendacji i celów, które powinniśmy sobie stawiać budując możliwe do utrzymania oprogramowanie, który zrozumie inny programista na podobnym do nas stanowisku.

Podobnie jak w przypadku reguł SOLID, zalecenia CUPID przetestujemy w sekcji ćwiczeń do tej lekcji.

### Zastosowanie na frontendzie

Wobec praktyk takich jak SOLID czy CUPID czasami pojawia się zarzut, że ich obiektowe (?) pochodzenie nie do końca łączy się z mocno funkcyjnym frontendem. Ile w tym prawdy?

**Komponenty wysokiej jakości**

Zacznijmy od komponentów, czyli podstawowej składowej współczesnych interfejsów użytkownika. W ich przypadku zdecydowanie powinniśmy stosować regułę “realizacji jednego zadania” oraz kompozycji w większą całość. Trudno wyobrazić sobie profesjonalną aplikację z jednym komponentem, który odpowiada za synchronizację całego interfejsu użytkownika. Nasz UI zwykle rozbijamy na mniejsze, możliwe do wymiany elementy. Zazwyczaj staramy się też odwzorować nazewnictwo domeny, w której te komponenty działają.

To nic innego jak trzy rekomendacje w jednym:

- Single Responsibility Principle (SOLID)
- Composability (CUPID)
- Domain-based naming (CUPID)
    

Planowanie nawet najprostszej struktury aplikacji to ćwiczenie, na które warto zdecydować się na początkowych etapach projektu. Pozwoli nam to określić konsekwencje takiego, a nie innego układu komponentów. Odkryjemy również wymagania związane ze stanem i przepływem danych, a cały zespół uzyska wspólne zrozumienie decyzji wpływających na skuteczne realizowanie projektu. Tę tematykę pogłębimy w ostatnim module poświęconym architekturze na frontendzie, a już w kolejnych lekcjach zobaczysz różne podejścia do zarządzania stanem, wynikające wprost z układu komponentów względem siebie.

A jeśli budujemy komunikację z API? Czy naprawdę biblioteki takie jak _axios_ lub _superagent_ powinny na nas wymuszać związanie się z nimi już na zawsze? Co w przypadku natywnego API _fetch_, które w pewnym momencie zaczęło być obowiązującym standardem? To właśnie czysty kod i wspomniane wyżej wzorce decydują o łatwości migracji do nowych standardów.

Jeśli nasze komponenty będą mocno powiązane z zewnętrznymi zależnościami, takimi jak konkretna biblioteka http, to przy jej ewentualnej aktualizacji będziemy mieć do wykonania mnóstwo pracy. Reguła odwrócenia zależności mówi, że tego typu zależności powinny być luźno powiązane z corem aplikacji i dostarczane z zewnątrz.

W przypadku Angulara, złamaniem tej zasady byłoby tworzenie instancji klienta http wewnątrz komponentu:

```typescript
class MyComponent {

  // Złamanie Dependency Inversion - MyComponent staje się mocno powiązany z AxiosService
  private http: HttpService = new AxiosService();

}
```

Zamiast tego, możemy polegać na wbudowanym systemie Dependency Injection, który umożliwia rozłączenie deklarowania zależności i korzystania z nich wewnątrz komponentów.

```typescript
class MyComponent {

  // MyComponent otrzyma instancję HttpService - konfiguracja znajduje się poza nim
  constructor(private http: HttpService) { ... }

}

// Tworzenie nowej instancji wraz z zastosowaniem Dependency Injection
// jest realizowane automatycznie na poziomie frameworka.
const cmp = new MyComponent(new AxiosService());
```

W przeciwieństwie do Angulara, React nie dostarcza natywnego systemu Dependency Injection, ale podobną separację komponentów i zależności możemy osiągnąć przez własne hooki.

W poniższym przykładzie komponent _ArticlesList_ korzysta z hooka _useArticlesClient_ który enkapsuluje (ukrywa) szczegóły implementacyjne pobierania danych. Dzięki temu zarówno sam hook można wykorzystać ponownie w innym komponencie, jak i sam komponent można w razie potrzeby łatwo przepiąć na inną bibliotekę http.

```typescript
import { ArticlePreview } from './ArticlePreview';
import { useArticlesClient } from './useArticlesClient';

export function ArticlesList() {
  const { articles, loading, error } = useArticlesClient();

  return (
    <>
      <h1 className="font-bold text-xl mb-4 text-gray-800">Articles</h1>
      {loading && <div>Loading...</div>}
      {error && <div>{error}</div>}
      <div className="flex flex-col space-y-2">
        {articles.map((article) => (
          <ArticlePreview key={article.id} {...article} />
        ))}
      </div>
    </>
  );
}
```

Wspomniany hook zobaczysz na przykładzie poniżej:

```typescript
import { useEffect, useState } from 'react';
import axios from 'axios';
import { Article, ArticleResponse } from './types';

export function useArticlesClient() {
  const [articles, setArticles] = useState<Article[]>([]);
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string>();

  useEffect(() => {
    setLoading(true);
    axios
      .get<ArticleResponse>(
        'http://localhost:3000/api/data/articles?timeout=2000'
      )
      .then(({ data: { articles } }) => {
        setArticles(articles);
      })
      .catch((error) => {
        setError('Cannot fetch articles!');
        console.error(error);
      })
      .finally(() => {
        setLoading(false);
      });
  }, []);

  return { articles, loading, error };
}
```

Dodatkową zaletą rozdzielania logiki biznesowej (hook) od warstwy widoku (komponent) jest refaktoryzacja kodu w kierunku jego testowalności. W ten wątek wejdziemy głębiej w drugim module, natomiast już teraz możesz zauważyć korzyści budowania funkcji, które nie są ściśle związane z konkretnym komponentem. W przypadku testowania pozwoli ci to unikać złożonej konfiguracji i inicjalizacji komponentów w testach, skupiając się na tym, co istotne z punktu widzenia wymagań biznesowych.

📝 Ten przykład znajdziesz w folderze **_examples/module1/lesson1/react-hooks_**.

W przypadku Vue, odwrócenie zależności realizowane jest poprzez funkcje [_provide_ oraz _inject_](https://vuejs.org/guide/components/provide-inject) - pierwsza odpowiada za rejestrację zależności w drzewie komponentów, a druga za wstrzyknięcie jej w odpowiednie miejsce w komponencie potomnym:

```tsx
<script setup>
// Parent component
import { provide } from 'vue';

provide('httpClient', new AxiosService());
</script>
```

```tsx
<script setup>
// Child component
import { inject } from 'vue';

const httpClient = inject('httpClient'); // instancja AxiosService
</script>
```

Zastanawiając się nad takim sposobem przekazywania danych możesz zapytać:

> -A dlaczego nie przez propsy?

Wyobraź sobie, że pomiędzy powyższymi komponentami jest sześć, osiem lub dziesięć dodatkowych warstw. W takim scenariuszu każdą porcję danych musielibyśmy przekazać z wykorzystaniem tzw. _prop drillingu_, czyli “przewiercania się” przez kolejne warstwy w drzewie komponentów (więcej o tym problemie w kolejnych lekcjach). Dzięki wstrzykiwaniu zależności, pracę wykonuje za nas framework, a funkcje provide/inject pozwalają uniknąć powtórzeń.

Jeśli zajdzie potrzeba wymiany Axiosa na innego klienta HTTP, całą operację możemy przeprowadzić na górze drzewa komponentów. Przy zachowaniu tego samego interfejsu dostępnych metod, komponenty potomne mogą zostać nienaruszone. Wrócimy do tego tematu w kolejnych lekcjach.

W każdym z trzech opisywanych frameworków szczegóły implementacyjne się różnią, ale końcowy cel, czyli luźne powiązanie zależności z komponentami jest stosunkowo proste do osiągnięcia.

**Komponent otwarty i zamknięty (jednocześnie)**

W teoretycznej części praktyk SOLID czytamy, że zgodność z Open-Closed Principle to tworzenie kodu:

- otwartego na rozszerzenia
    
- zamkniętego na zmiany
    

W jaki sposób jeden komponent może realizować oba te założenia jednocześnie? Czy nowe wymagania biznesowe nie powinny każdorazowo zmuszać programisty do modyfikacji wcześniej napisanych linijek kodu?

Okazuje się, że istnieją techniki łączące te pozornie sprzeczne wymagania. Zobacz, jak technika _render props_ pozwala zaimplementować rekomendację Open-Closed Principle:

Render props to jedna z wielu technik implementacji Open-Closed Principle w praktyce. Jak rozpoznać, kiedy ta praktyka przyda się w twoich projektach? Zawsze wtedy, kiedy w projekcie dana nowość lub rozszerzenie ma zależność czasową, rozważ zastosowanie tej zasady. Przykładowo:

- “Dzisiaj dodajemy 5 filtrów do tabeli, ale w kolejnych kwartałach będą nowe”
    
- “Dzisiaj dodajemy 3 widgety, ale w przyszłości musi być ich więcej”
    
- “Dzisiaj na dashboardzie są 4 typy wykresów, ale chcemy wspierać 8”
    

W każdym z tych scenariuszy element “Open” dotyczy pozostawania otwartym na nowości, a “Closed” dotyczy spójnego mechanizmu, które zaimplementujesz na samym początku. Zamknięcie danej funkcjonalności może chociażby polegać na zdefiniowaniu jednego interfejsu, którego będą musiały się trzymać wszystkie kolejne rozszerzenia:

```typescript
// Format danych w tabeli
interface TableRow {
  name: string;
  age: number;
  city: string;
}

// Generyczny interfejs do obsługi filtrowania danych
interface TableFilter<T extends TableRow> {
  apply(data: T[]): T[];
}

// Implementacja filtrowania po nazwie
class NameFilter implements TableFilter<TableRow> {
  private name: string;

  constructor(name: string) {
    this.name = name;
  }

  apply(data: TableRow[]): TableRow[] {
    return data.filter((row) => row.name === this.name);
  }
}

// Implementacja filtrowania po wieku
class AgeFilter implements TableFilter<TableRow> {
  private age: number;

  constructor(age: number) {
    this.age = age;
  }

  apply(data: TableRow[]): TableRow[] {
    return data.filter((row) => row.age === this.age);
  }
}

// Przykładowe dane do tabeli
const data: TableRow[] = [
  {name: "Alice", age: 30, city: "New York"},
  {name: "Bob", age: 25, city: "San Francisco"},
  {name: "Alice", age: 29, city: "Los Angeles"},
];

// Open - zestaw filtrów jest otwarty na rozszerzenia i jest to zadanie niskiego ryzyka
const filters: TableFilter<TableRow>[] = [
  new NameFilter("Alice"),
  new AgeFilter(30),
];

// Closed - jednolita obsługa filtrowania - warte przetestowania i zabezpieczenia
function applyFilters<T extends TableRow>(
  data: T[],
  filters: TableFilter<T>[]
): T[] {
  return filters.reduce(
    (filteredData, filter) => filter.apply(filteredData),
    data
  );
}

let filteredData = applyFilters(data, filters);
console.log(filteredData);
```

W obu przypadkach _TableFilter_ wprowadza regułę - jeśli chcesz wspierać nowy typ filtrowania danych, zaimplementuj klasę z funkcją “apply”, która przyjmie pewien zestaw danych i odpowiednio go ograniczy. Od strony konsumenta filtrów wiesz, że cały wysiłek sprowadzi się wtedy do jednorazowej implementacji funkcji “applyFilters”, która przetworzy bazowy zestaw danych i konfigurację filtrów. Takie podejście pozwoli ci z łatwością rozszerzać kod i udostępniać go innym osobom.

Najważniejszy element tej rekomendacji dotyczy określenia tego, jakie fragmenty interfejsu użytkownika, modułu lub komponentu powinny być ukryte przed światem zewnętrznym, a jakie można konfigurować w dowolny sposób. Pisząc nasz kod w ten sposób minimalizujemy ryzyko wprowadzania błędów przy jednoczesnym zachowaniu oczekiwanej elastyczności. Win-win!

**Inspiracje systemami Unix**

CUPID wspomina o rozwijaniu kodu zgodnie z tzw. filozofią Unixa (Unix Philosophy). W systemach UNIXowych promowane są małe programy (awk, grep, tr, itd.), które przy pomocy operatora _pipe_ mogą przekazywać sobie nawzajem dane i łączyć się w realizacji większego zadania:

```bash
echo "1 4 6 8 10" | 
  tr ' ' '\n' |                  # Podział na wiele wierszy
  awk '{print $1*2}' |           # Mnożenie przez 2
  awk '$1<=10' |                 # Filtrowanie
  awk '{sum+=$1} END {print sum}' # Sumowanie
```

Naprawdę warto zastanowić się przez chwilę jak eleganckie jest to rozwiązanie. Narzędzia mają ściśle określoną rolę, muszą być odpowiednio elastyczne i otwarte na różne konteksty użycia, a wymiana lub ulepszenie jednego z nich nie zmusza nas do modyfikacji reszty (im mniej kodu musimy zmieniać, tym mniejsza szansa na wprowadzenie potencjalnych błędów).

Jak możemy się inspirować Unix Philosophy na frontendzie? Zamiast imperatywnych poleceń opisywanych krok po kroku (wyrażenia warunkowe, pętle for, etc.), na frontendzie przyjętą konwencją jest korzystanie z mikro-narzędzi i funkcji wyższego rzędu (_map, filter, reduce_), które możemy ze sobą łączyć.

Dzięki temu z kodu o takim kształcie…

```javascript
const numbers = [1, 4, 6, 8, 10];
let sum = 0;

for (let i = 0; i < numbers.length; i++) {
    const doubled = numbers[i] * 2;
    if (doubled <= 10) {
        sum += doubled;
    }
}

console.log(sum);
```

…możemy przejść na elegancki, deklaratywny łańcuch możliwych do łączenia funkcji:

```javascript
const numbers = [1, 4, 6, 8, 10];

const result = numbers
  .map(num => num * 2)
  .filter(num => num <= 10)
  .reduce((sum, num) => sum + num, 0);

console.log(result);
```

Pisząc kod w ten sposób, detale takie jak indeksy, warunki zatrzymania funkcji czy zmienne pomocnicze nie są nam potrzebne. Znowu - im mniejsza złożoność kodu, tym mniej okazji do popełniania błędów.

Nie zawsze uzyskamy w ten sposób kod bardziej wydajny (liczba wykonań pętli się zwiększa), ale często zdecydowanie łatwiejszy w utrzymaniu.

Korzyści wynikające ze stosowania praktyk takich jak SOLID czy CUPID docenia z biegiem czasu niemal każdy programista. Chociaż nie są to zasady wymuszane przez środowisko programistyczne, a ich złamanie nie grozi odebraniem licencji na programowanie, przyjmuje się je za wskaźnik oprogramowania wysokiej jakości.

## Refaktoryzacja kodu zastanego

Wraz ze wzrostem doświadczenia będziesz poznawał kolejne wzorce i dobre praktyki, które pozytywnie wpływają na całościową jakość projektu. W pewnym momencie może pojawić się dylemat - czy wprowadzać je stopniowo, zaczynając od najmniejszych możliwych części projektu, czy może postawić na duży refaktoring (czyli proces podnoszenia jakości kodu w aplikacji), który zacznie się już na samej górze drzewa komponentów?

Oba podejścia mają swoje plusy i minusy, a szczegóły poznasz poniżej:

### **Podejście “Top-down”**

Na całościowe przepisanie aplikacji decydujemy się zazwyczaj wtedy, kiedy sytuacja jest naprawdę poważna, lub kiedy chcemy wprowadzić radykalne usprawnienia np. na poziomie stacku technologicznego (wymiana frameworka). W tym podejściu nowa, ulepszona wersja aplikacji powstaje niezależnie od tej wdrożonej na produkcji. W momencie, kiedy funkcjonalności są odwzorowane 1:1 można zadecydować o zastąpieniu poprzedniej wersji aplikacji tą nową, z lepszą architekturą lub nowoczesnymi fundamentami.

**Plusy tego podejścia:**

- przestrzeń na wdrożenie istotnej zmiany architektury i stosu technologicznego
    
- kontynuacja pracy nad aktualną wersją aplikacji przebiega bez zakłóceń
    
- część zespołu może skupić się na nowym, niezależnym projekcie
    

**Minusy tego podejścia:**

- długi czas trwania całego projektu, od jego rozpoczęcia do wdrożenia na produkcję
    
- wymagane utrzymywanie dwóch spójnych wersji aplikacji - starej i nowej
    
- ryzyko zmiany planów i porzucenia projektu przed wdrożeniem na produkcję
    

### **Podejście “Bottom-up”**

W tym podejściu core naszej aplikacji pozostaje stabilny, a my skupiamy się na ulepszaniu najmniejszych możliwych elementów aplikacji. W przypadku frontendu i interfejsów użytkownika, dobrze rozumianą granicą zmian jest poziom pojedynczego komponentu. Oczywiście nie musimy pozostać na jednym komponencie, ale możemy tutaj zmieniać zestaw kilku współpracujących ze sobą elementów.

**Plusy tego podejścia:**

- możliwość ciągłego i regularnego wdrażania usprawnień aplikacji na produkcję
    
- mniejsze ryzyko “rozjazdu” dwóch alternatywnych wersji aplikacji (por. podejście top-down)
    
- łatwiejszy model pracy dla mniejszych zespołów o ograniczonych zasobach
    

**Minusy tego podejścia:**

- duże błędy na poziomie architektury mogą być niemożliwe do usunięcia
    
- skupiając się na lokalnych usprawnieniach możemy stracić z oczu całościowy obraz projektu
    
- czas przeznaczany na zmiany lokalne może nie dawać odczuwalnych korzyści dla użytkownika
    

### **Które podejście wybrać?**

Chociaż oba podejścia mają swoje plusy i minusy, to zgodnie ze zwinnymi praktykami rozwoju oprogramowania zdecydowanie łatwiej realizować refaktoryzację w podejściu bottom-up. Pozwala ona na bardziej elastyczny model wdrażania zmian, nie wymaga tak dużego narzutu komunikacyjnego jak podejście top-down i zmniejsza wymagany próg wejścia dla tych programistów, którzy chcą w projekcie dodać coś od siebie. Model komponentowy, który jest obecnym standardem budowania frontendu, ułatwia wdrażanie zmian właśnie w tym modelu, a komponenty wyznaczają granicę refaktoryzacji, nad którą pracujemy.

Radykalne zmiany architektury, wymiana frameworka lub całych fundamentów aplikacji (tak jak w top-down) to zdecydowanie większe ryzyko, trudniejsze dyskusje z przełożonymi i potencjalnie oddalająca się linia mety, której czasami nigdy nie uda się przekroczyć. Właśnie dlatego przepisywanie i wymiana całych aplikacji to najbardziej radykalny krok, którego wielu doświadczonych programistów stara się zupełnie unikać.

## Podsumowanie

W naszym kursie podkreślamy, że opisywane tutaj praktyki to tylko i wyłącznie narzędzia, a nie cele twojej przygody z programowaniem. Można je traktować jak obszerne notatki i podsumowania eksperymentów, które pozostawili po sobie bardziej doświadczeni programiści z przeszłości.

Poznając i stosując te najbardziej użyteczne rekomendacje, oszczędzasz cenny czas i energię. Zamiast odkrywać koło na nowo, możesz w swoich projektach stosować gotowe przepisy na rozwiązania problemów z którymi spotykano się już wielokrotnie.

Zanim zdecydujesz się z nich zrezygnować, ważne jest abyś rozumiał, dlaczego zostały one opracowane i jaka była oryginalna intencja autora. Ta wiedza pozwoli Ci dokonać przemyślanych wyborów na poziomie stacku technologicznego, projektowania architektury czy implementowania nowych wymagań biznesowych.

W kolejnej lekcji poznasz zestaw najbardziej popularnych wzorców projektowych, które na szeroką skalę stosują autorzy najpopularniejszych bibliotek i frameworków.